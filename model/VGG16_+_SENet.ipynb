{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZxviaB_3Vm2V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchsummary\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU 사용 & Seed값 조정\n"
      ],
      "metadata": {
        "id": "wJWH7oa4XW3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# == GPU ==\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# == Seed값 ==\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed(777)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tdD350OXWMV",
        "outputId": "e682eddc-7405-4586-8679-32a1cfd05702"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78b7f0141610>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "OlV1rzQuXagD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train(flag = True):\n",
        "  train = dsets.CIFAR10(root = '/content/data',\n",
        "                        train = True,\n",
        "                        download = True)\n",
        "\n",
        "  test = dsets.CIFAR10(root = '/content/data',\n",
        "                       train = False,\n",
        "                       download = True)\n",
        "\n",
        "  return train, test\n",
        "\n",
        "train, test = get_train(flag = True)\n",
        "\n",
        "print('Train Lenght : ', len(train))\n",
        "print('Test Lenght : ', len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l_d2UWPXY4N",
        "outputId": "445955cf-6787-4096-b32f-392280a9ec6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13155001.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/cifar-10-python.tar.gz to /content/data\n",
            "Files already downloaded and verified\n",
            "Train Lenght :  50000\n",
            "Test Lenght :  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "YEPLf_XIX3TA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.transform = transforms.ToTensor()\n",
        "test.transform = transforms.ToTensor()\n",
        "\n",
        "train_meanRGB = [np.mean(x.numpy(), axis = (1, 2)) for x, _ in train]\n",
        "train_stdRGB = [np.std(x.numpy(), axis = (1, 2)) for x, _ in train]\n",
        "\n",
        "meanR = np.mean([m[0] for m in train_meanRGB])\n",
        "meanG = np.mean([m[1] for m in train_meanRGB])\n",
        "meanB = np.mean([m[2] for m in train_meanRGB])\n",
        "\n",
        "stdR = np.mean([s[0] for s in train_stdRGB])\n",
        "stdG = np.mean([s[1] for s in train_stdRGB])\n",
        "stdB = np.mean([s[2] for s in train_stdRGB])\n",
        "\n",
        "train_mean = [meanR, meanG, meanB]\n",
        "train_std = [stdR, stdG, stdB]\n",
        "\n",
        "test_meanRGB = [np.mean(x.numpy(), axis = (1, 2)) for x, _ in test]\n",
        "test_stdRGB = [np.std(x.numpy(), axis = (1, 2)) for x, _ in test]\n",
        "\n",
        "meanR = np.mean([m[0] for m in test_meanRGB])\n",
        "meanG = np.mean([m[1] for m in test_meanRGB])\n",
        "meanB = np.mean([m[2] for m in test_meanRGB])\n",
        "\n",
        "stdR = np.mean([s[0] for s in test_stdRGB])\n",
        "stdG = np.mean([s[1] for s in test_stdRGB])\n",
        "stdB = np.mean([s[2] for s in test_stdRGB])\n",
        "\n",
        "\n",
        "test_mean = [meanR, meanG, meanB]\n",
        "test_std = [stdR, stdG, stdB]\n",
        "\n",
        "print(' == == == == Train == == == ==')\n",
        "print('각 Channel당 pixel Mean 값 : ', train_mean)\n",
        "print('각 Channel당 pixel Std 값 : ', train_std)\n",
        "print(' == == == == == == == == == ==')\n",
        "\n",
        "print(' == == == == Test == == == ==')\n",
        "print('각 Channel당 pixel Mean 값 : ', test_mean)\n",
        "print('각 Channel당 pixel Std 값 : ', test_std)\n",
        "print(' == == == == == == == == == ==')"
      ],
      "metadata": {
        "id": "BG5EolqwXuYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c691279-c90b-4964-f89f-78f4c4c98284"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " == == == == Train == == == ==\n",
            "각 Channel당 pixel Mean 값 :  [0.49139965, 0.48215845, 0.4465309]\n",
            "각 Channel당 pixel Std 값 :  [0.20220213, 0.19931543, 0.20086348]\n",
            " == == == == == == == == == ==\n",
            " == == == == Test == == == ==\n",
            "각 Channel당 pixel Mean 값 :  [0.49421427, 0.48513138, 0.45040908]\n",
            "각 Channel당 pixel Std 값 :  [0.20189482, 0.19902097, 0.20103233]\n",
            " == == == == == == == == == ==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "j5xpLPtpYNDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness = 0.2, contrast = 0.2, saturation = 0.2, hue = 0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_mean, train_std)\n",
        "])\n",
        "\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(test_mean, test_std)\n",
        "])\n",
        "\n",
        "train.transform = train_tf\n",
        "test.transform = test_tf"
      ],
      "metadata": {
        "id": "JTxjF-fVX6vs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 구현"
      ],
      "metadata": {
        "id": "Q2_8SerPzqnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SEblock"
      ],
      "metadata": {
        "id": "A5OJBVFczsx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEblock(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(SEblock, self).__init__()\n",
        "        self.squeeze_avg = nn.AdaptiveAvgPool2d(1)\n",
        "        self.excitation = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_channels // reduction, in_channels, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.squeeze_avg(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.excitation(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        return x * out"
      ],
      "metadata": {
        "id": "ZCyEtfmtzuI5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16 + SEblock"
      ],
      "metadata": {
        "id": "XQB4JS2_ZCRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG16, self).__init__()\n",
        "\n",
        "    self.num_class = 1000 # cifar10은 10개의 class\n",
        "    self.conv = self._make_conv_layers([64, 128, 128, 256, 512, 512], [2, 2, 2, 2, 2, 2])\n",
        "    self.fc = self._fc_layers()\n",
        "    self._initialize_weights()\n",
        "\n",
        "\n",
        "  def _make_conv_layers(self, channels, blocks):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "\n",
        "    # 1x1 conv도 있다는 것을 명심\n",
        "    for i, (out_channels, block_count) in enumerate(zip(channels, blocks), 1):\n",
        "      for _ in range(block_count):\n",
        "        layers.append(self._conv_layers(in_channels, out_channels))\n",
        "        in_channels = out_channels\n",
        "\n",
        "      # 1x1 conv -> 4~6번째 layer\n",
        "      if i >= 4:\n",
        "        layers.append(self._conv_layers(in_channels, out_channels, kernel_size = 1, padding = 0))\n",
        "\n",
        "      # 마지막 layer에는 maxpooling 없음\n",
        "      if i < 6:\n",
        "        layers.append(nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  # == Conv ==\n",
        "  def _conv_layers(self, in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        SEblock(out_channels), # SEblock 추가함\n",
        "        nn.ReLU(inplace = True)\n",
        "    )\n",
        "\n",
        "  # == Fc ==\n",
        "  def _fc_layers(self):\n",
        "    feature_vector = 512 * 7 * 7\n",
        "    return nn.Sequential(\n",
        "        # fc 1\n",
        "\n",
        "        nn.Linear(feature_vector, 4096),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(p = 0.5),\n",
        "\n",
        "        # fc 2\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(p = 0.5),\n",
        "\n",
        "        # output layer\n",
        "        nn.Linear(4096, self.num_class)\n",
        "    )\n",
        "\n",
        "  # == 가중치 초기화 ==\n",
        "  def _initialize_weights(self):\n",
        "    for layer in self.modules():\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
        "            if layer.bias is not None:\n",
        "                nn.init.constant_(layer.bias, 0)\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            nn.init.normal_(layer.weight, 0, 0.01)\n",
        "            if layer.bias is not None:\n",
        "                nn.init.constant_(layer.bias, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "wQ0ISsnuZAAh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16().to(device)\n",
        "torchsummary.summary(model, input_size = (3, 224, 224), device = 'cuda')"
      ],
      "metadata": {
        "id": "ippcE_3o-Owe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e7ede9-4a3d-423a-80d4-f7fcfe67825a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
            " AdaptiveAvgPool2d-3             [-1, 64, 1, 1]               0\n",
            "            Linear-4                    [-1, 4]             256\n",
            "              ReLU-5                    [-1, 4]               0\n",
            "            Linear-6                   [-1, 64]             256\n",
            "           Sigmoid-7                   [-1, 64]               0\n",
            "           SEblock-8         [-1, 64, 224, 224]               0\n",
            "              ReLU-9         [-1, 64, 224, 224]               0\n",
            "           Conv2d-10         [-1, 64, 224, 224]          36,928\n",
            "      BatchNorm2d-11         [-1, 64, 224, 224]             128\n",
            "AdaptiveAvgPool2d-12             [-1, 64, 1, 1]               0\n",
            "           Linear-13                    [-1, 4]             256\n",
            "             ReLU-14                    [-1, 4]               0\n",
            "           Linear-15                   [-1, 64]             256\n",
            "          Sigmoid-16                   [-1, 64]               0\n",
            "          SEblock-17         [-1, 64, 224, 224]               0\n",
            "             ReLU-18         [-1, 64, 224, 224]               0\n",
            "        MaxPool2d-19         [-1, 64, 112, 112]               0\n",
            "           Conv2d-20        [-1, 128, 112, 112]          73,856\n",
            "      BatchNorm2d-21        [-1, 128, 112, 112]             256\n",
            "AdaptiveAvgPool2d-22            [-1, 128, 1, 1]               0\n",
            "           Linear-23                    [-1, 8]           1,024\n",
            "             ReLU-24                    [-1, 8]               0\n",
            "           Linear-25                  [-1, 128]           1,024\n",
            "          Sigmoid-26                  [-1, 128]               0\n",
            "          SEblock-27        [-1, 128, 112, 112]               0\n",
            "             ReLU-28        [-1, 128, 112, 112]               0\n",
            "           Conv2d-29        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-30        [-1, 128, 112, 112]             256\n",
            "AdaptiveAvgPool2d-31            [-1, 128, 1, 1]               0\n",
            "           Linear-32                    [-1, 8]           1,024\n",
            "             ReLU-33                    [-1, 8]               0\n",
            "           Linear-34                  [-1, 128]           1,024\n",
            "          Sigmoid-35                  [-1, 128]               0\n",
            "          SEblock-36        [-1, 128, 112, 112]               0\n",
            "             ReLU-37        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-38          [-1, 128, 56, 56]               0\n",
            "           Conv2d-39          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-40          [-1, 128, 56, 56]             256\n",
            "AdaptiveAvgPool2d-41            [-1, 128, 1, 1]               0\n",
            "           Linear-42                    [-1, 8]           1,024\n",
            "             ReLU-43                    [-1, 8]               0\n",
            "           Linear-44                  [-1, 128]           1,024\n",
            "          Sigmoid-45                  [-1, 128]               0\n",
            "          SEblock-46          [-1, 128, 56, 56]               0\n",
            "             ReLU-47          [-1, 128, 56, 56]               0\n",
            "           Conv2d-48          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-49          [-1, 128, 56, 56]             256\n",
            "AdaptiveAvgPool2d-50            [-1, 128, 1, 1]               0\n",
            "           Linear-51                    [-1, 8]           1,024\n",
            "             ReLU-52                    [-1, 8]               0\n",
            "           Linear-53                  [-1, 128]           1,024\n",
            "          Sigmoid-54                  [-1, 128]               0\n",
            "          SEblock-55          [-1, 128, 56, 56]               0\n",
            "             ReLU-56          [-1, 128, 56, 56]               0\n",
            "        MaxPool2d-57          [-1, 128, 28, 28]               0\n",
            "           Conv2d-58          [-1, 256, 28, 28]         295,168\n",
            "      BatchNorm2d-59          [-1, 256, 28, 28]             512\n",
            "AdaptiveAvgPool2d-60            [-1, 256, 1, 1]               0\n",
            "           Linear-61                   [-1, 16]           4,096\n",
            "             ReLU-62                   [-1, 16]               0\n",
            "           Linear-63                  [-1, 256]           4,096\n",
            "          Sigmoid-64                  [-1, 256]               0\n",
            "          SEblock-65          [-1, 256, 28, 28]               0\n",
            "             ReLU-66          [-1, 256, 28, 28]               0\n",
            "           Conv2d-67          [-1, 256, 28, 28]         590,080\n",
            "      BatchNorm2d-68          [-1, 256, 28, 28]             512\n",
            "AdaptiveAvgPool2d-69            [-1, 256, 1, 1]               0\n",
            "           Linear-70                   [-1, 16]           4,096\n",
            "             ReLU-71                   [-1, 16]               0\n",
            "           Linear-72                  [-1, 256]           4,096\n",
            "          Sigmoid-73                  [-1, 256]               0\n",
            "          SEblock-74          [-1, 256, 28, 28]               0\n",
            "             ReLU-75          [-1, 256, 28, 28]               0\n",
            "           Conv2d-76          [-1, 256, 28, 28]          65,792\n",
            "      BatchNorm2d-77          [-1, 256, 28, 28]             512\n",
            "AdaptiveAvgPool2d-78            [-1, 256, 1, 1]               0\n",
            "           Linear-79                   [-1, 16]           4,096\n",
            "             ReLU-80                   [-1, 16]               0\n",
            "           Linear-81                  [-1, 256]           4,096\n",
            "          Sigmoid-82                  [-1, 256]               0\n",
            "          SEblock-83          [-1, 256, 28, 28]               0\n",
            "             ReLU-84          [-1, 256, 28, 28]               0\n",
            "        MaxPool2d-85          [-1, 256, 14, 14]               0\n",
            "           Conv2d-86          [-1, 512, 14, 14]       1,180,160\n",
            "      BatchNorm2d-87          [-1, 512, 14, 14]           1,024\n",
            "AdaptiveAvgPool2d-88            [-1, 512, 1, 1]               0\n",
            "           Linear-89                   [-1, 32]          16,384\n",
            "             ReLU-90                   [-1, 32]               0\n",
            "           Linear-91                  [-1, 512]          16,384\n",
            "          Sigmoid-92                  [-1, 512]               0\n",
            "          SEblock-93          [-1, 512, 14, 14]               0\n",
            "             ReLU-94          [-1, 512, 14, 14]               0\n",
            "           Conv2d-95          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-96          [-1, 512, 14, 14]           1,024\n",
            "AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0\n",
            "           Linear-98                   [-1, 32]          16,384\n",
            "             ReLU-99                   [-1, 32]               0\n",
            "          Linear-100                  [-1, 512]          16,384\n",
            "         Sigmoid-101                  [-1, 512]               0\n",
            "         SEblock-102          [-1, 512, 14, 14]               0\n",
            "            ReLU-103          [-1, 512, 14, 14]               0\n",
            "          Conv2d-104          [-1, 512, 14, 14]         262,656\n",
            "     BatchNorm2d-105          [-1, 512, 14, 14]           1,024\n",
            "AdaptiveAvgPool2d-106            [-1, 512, 1, 1]               0\n",
            "          Linear-107                   [-1, 32]          16,384\n",
            "            ReLU-108                   [-1, 32]               0\n",
            "          Linear-109                  [-1, 512]          16,384\n",
            "         Sigmoid-110                  [-1, 512]               0\n",
            "         SEblock-111          [-1, 512, 14, 14]               0\n",
            "            ReLU-112          [-1, 512, 14, 14]               0\n",
            "       MaxPool2d-113            [-1, 512, 7, 7]               0\n",
            "          Conv2d-114            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-115            [-1, 512, 7, 7]           1,024\n",
            "AdaptiveAvgPool2d-116            [-1, 512, 1, 1]               0\n",
            "          Linear-117                   [-1, 32]          16,384\n",
            "            ReLU-118                   [-1, 32]               0\n",
            "          Linear-119                  [-1, 512]          16,384\n",
            "         Sigmoid-120                  [-1, 512]               0\n",
            "         SEblock-121            [-1, 512, 7, 7]               0\n",
            "            ReLU-122            [-1, 512, 7, 7]               0\n",
            "          Conv2d-123            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-124            [-1, 512, 7, 7]           1,024\n",
            "AdaptiveAvgPool2d-125            [-1, 512, 1, 1]               0\n",
            "          Linear-126                   [-1, 32]          16,384\n",
            "            ReLU-127                   [-1, 32]               0\n",
            "          Linear-128                  [-1, 512]          16,384\n",
            "         Sigmoid-129                  [-1, 512]               0\n",
            "         SEblock-130            [-1, 512, 7, 7]               0\n",
            "            ReLU-131            [-1, 512, 7, 7]               0\n",
            "          Conv2d-132            [-1, 512, 7, 7]         262,656\n",
            "     BatchNorm2d-133            [-1, 512, 7, 7]           1,024\n",
            "AdaptiveAvgPool2d-134            [-1, 512, 1, 1]               0\n",
            "          Linear-135                   [-1, 32]          16,384\n",
            "            ReLU-136                   [-1, 32]               0\n",
            "          Linear-137                  [-1, 512]          16,384\n",
            "         Sigmoid-138                  [-1, 512]               0\n",
            "         SEblock-139            [-1, 512, 7, 7]               0\n",
            "            ReLU-140            [-1, 512, 7, 7]               0\n",
            "          Linear-141                 [-1, 4096]     102,764,544\n",
            "            ReLU-142                 [-1, 4096]               0\n",
            "         Dropout-143                 [-1, 4096]               0\n",
            "          Linear-144                 [-1, 4096]      16,781,312\n",
            "            ReLU-145                 [-1, 4096]               0\n",
            "         Dropout-146                 [-1, 4096]               0\n",
            "          Linear-147                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 134,173,480\n",
            "Trainable params: 134,173,480\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 359.19\n",
            "Params size (MB): 511.83\n",
            "Estimated Total Size (MB): 871.59\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Train & Valid"
      ],
      "metadata": {
        "id": "g9KGBsxTFO15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9\n",
        "weight_decay = 0.00005\n",
        "learnign_rate = 0.01\n",
        "epochs = 10 # 10으로 조정"
      ],
      "metadata": {
        "id": "Dfl61pvUAhd5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# == split train, valud ==\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.2\n",
        "\n",
        "train_size = int(len(train) * train_ratio)\n",
        "val_size = len(train) - train_size\n",
        "\n",
        "split_train, split_train = random_split(train, [train_size, val_size])"
      ],
      "metadata": {
        "id": "OpAPDuSFFS12"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = split_train,\n",
        "                                           batch_size=  batch_size,\n",
        "                                           shuffle = True,\n",
        "                                           drop_last = True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset = split_train,\n",
        "                                        batch_size = batch_size,\n",
        "                                        shuffle = True,\n",
        "                                        drop_last = True)"
      ],
      "metadata": {
        "id": "OIoUc7LpFYI4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = momentum, weight_decay = weight_decay)\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "PGTtkyZGFZxJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: 반복적인 학습\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # 모델을 학습 모드로 설정\n",
        "\n",
        "\n",
        "    '''\n",
        "    1. for문 1번 반복할때마다 batch_idx는 batch_size만큼 증가\n",
        "     ex) 1 iter: 0 ~ 127\n",
        "         2 iter: 128 ~ 255\n",
        "\n",
        "         전체 훈련 데이터를 다 쓰기전까지 반복.\n",
        "    '''\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # 데이터와 레이블을 GPU로 이동 (if available)\n",
        "        # data = data.view(-1, 3, 224, 224) # multi-crop 대체\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Forward 연산\n",
        "        output = model(data)\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward 연산 및 매개변수 업데이트\n",
        "        optimizer.zero_grad() # 미분값 중복 방지\n",
        "        loss.backward() # 오차역전파\n",
        "        optimizer.step() # parameter 업데이트\n",
        "\n",
        "        # 일정 간격으로 손실 출력\n",
        "\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            #print(len(train_loader)) 항상 312로 동일한 값\n",
        "            print(batch_idx)\n",
        "            print('Epoch {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch + 1, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item())) # 100.은 실수형을 말한다.(실수형으로 출력하기 위함)\n",
        "                # len(train_loader)는 배치 개수를 나타낸다. 여기서는 312개(312번 가중치 update)\n",
        "\n",
        "    # 검증 데이터셋을 사용한 모델 평가\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # 미분값 계산 x\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Forward 계산\n",
        "            output = model(data)\n",
        "\n",
        "            val_loss += criterion(output, target).item() # 손실함수 계산\n",
        "            pred = output.argmax(dim=1, keepdim=True) # 예측값(행마다)에서 가장 큰 값의 인덱스 가져옴, (n, 1)형식\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() # target을 pred와 같은 shape으로 만들어준다.\n",
        "            '''\n",
        "            .eq()는 두 tensor의 shape이 동일해야 비교 연산이 가능하다.\n",
        "            '''\n",
        "\n",
        "    val_loss /= len(val_loader.dataset) # 검증 손실함수\n",
        "    val_accuracy = 100. * correct / len(val_loader.dataset) # 검증 정확도\n",
        "\n",
        "    # 검증 결과 출력\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        val_loss, correct, len(val_loader.dataset), val_accuracy))"
      ],
      "metadata": {
        "id": "Uuk4rrAcFbcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254f86a3-a53f-4029-92e9-b363a4249a4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch 1 [0/10000 (0%)]\tLoss: 6.883774\n",
            "100\n",
            "Epoch 1 [6400/10000 (64%)]\tLoss: 1.907132\n",
            "\n",
            "Validation set: Average loss: 0.0326, Accuracy: 2797/10000 (27.97%)\n",
            "\n",
            "0\n",
            "Epoch 2 [0/10000 (0%)]\tLoss: 1.898115\n",
            "100\n",
            "Epoch 2 [6400/10000 (64%)]\tLoss: 1.670009\n",
            "\n",
            "Validation set: Average loss: 0.0283, Accuracy: 3464/10000 (34.64%)\n",
            "\n",
            "0\n",
            "Epoch 3 [0/10000 (0%)]\tLoss: 1.669800\n",
            "100\n",
            "Epoch 3 [6400/10000 (64%)]\tLoss: 1.724066\n",
            "\n",
            "Validation set: Average loss: 0.0248, Accuracy: 4315/10000 (43.15%)\n",
            "\n",
            "0\n",
            "Epoch 4 [0/10000 (0%)]\tLoss: 1.725388\n",
            "100\n",
            "Epoch 4 [6400/10000 (64%)]\tLoss: 1.561356\n",
            "\n",
            "Validation set: Average loss: 0.0217, Accuracy: 4975/10000 (49.75%)\n",
            "\n",
            "0\n",
            "Epoch 5 [0/10000 (0%)]\tLoss: 1.525549\n",
            "100\n",
            "Epoch 5 [6400/10000 (64%)]\tLoss: 1.255056\n",
            "\n",
            "Validation set: Average loss: 0.0204, Accuracy: 5396/10000 (53.96%)\n",
            "\n",
            "0\n",
            "Epoch 6 [0/10000 (0%)]\tLoss: 1.224671\n",
            "100\n",
            "Epoch 6 [6400/10000 (64%)]\tLoss: 1.362809\n",
            "\n",
            "Validation set: Average loss: 0.0195, Accuracy: 5589/10000 (55.89%)\n",
            "\n",
            "0\n",
            "Epoch 7 [0/10000 (0%)]\tLoss: 1.329640\n",
            "100\n",
            "Epoch 7 [6400/10000 (64%)]\tLoss: 1.098450\n",
            "\n",
            "Validation set: Average loss: 0.0187, Accuracy: 5688/10000 (56.88%)\n",
            "\n",
            "0\n",
            "Epoch 8 [0/10000 (0%)]\tLoss: 0.975520\n",
            "100\n",
            "Epoch 8 [6400/10000 (64%)]\tLoss: 0.930285\n",
            "\n",
            "Validation set: Average loss: 0.0164, Accuracy: 6297/10000 (62.97%)\n",
            "\n",
            "0\n",
            "Epoch 9 [0/10000 (0%)]\tLoss: 0.969363\n",
            "100\n",
            "Epoch 9 [6400/10000 (64%)]\tLoss: 0.737929\n",
            "\n",
            "Validation set: Average loss: 0.0140, Accuracy: 6806/10000 (68.06%)\n",
            "\n",
            "0\n",
            "Epoch 10 [0/10000 (0%)]\tLoss: 0.964726\n",
            "100\n",
            "Epoch 10 [6400/10000 (64%)]\tLoss: 0.962295\n",
            "\n",
            "Validation set: Average loss: 0.0132, Accuracy: 7018/10000 (70.18%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 테스트"
      ],
      "metadata": {
        "id": "izRa5u56Fej4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(test,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = False,\n",
        "                                          drop_last = True)"
      ],
      "metadata": {
        "id": "4Li-MzDzFfU7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1) # 가장 높은값의 인덱스, 값 반환 --> 여기서는 가장 높은 값만 반환했다.\n",
        "\n",
        "    total += labels.size(0) # 전체 데이터 예측 개수(len(cifar_test_loader) 와 같다)\n",
        "    correct += (predicted == labels.to(torch.long)).sum().item() # predicted, labels의 텐서 타입이 일치하지 않아서 long으로 바꾸어줌.\n",
        "    # 맞으면 correct에 true, 틀리면 false 반환한다. 맞은 것만 개수 센다.\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy : {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsJekY0YTJzw",
        "outputId": "77c60f0e-64b6-457a-e317-3f4d38e642fd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 65.87540064102564\n"
          ]
        }
      ]
    }
  ]
}