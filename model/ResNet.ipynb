{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XsGDZMvGQV2b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchsummary\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import StepLR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU 사용"
      ],
      "metadata": {
        "id": "PiJDRwzwQvO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device == \"cuda\":\n",
        "  torch.cuda.manual_seed(777)\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq-9-f7RQoSx",
        "outputId": "d4fc149a-f69a-45eb-ad5a-c39211fc54f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CIFAR10 Train, Test 이미지 얻기"
      ],
      "metadata": {
        "id": "akNYUJWiQ2Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# == Cifar10 데이터 얻기 ==\n",
        "def get_data(flag = True):\n",
        "    train = dsets.CIFAR10(root = '/data',\n",
        "                          train = True,\n",
        "                          download = True)\n",
        "    test = dsets.CIFAR10(root = '/data',\n",
        "                        train = False,\n",
        "                        download = True)\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "EJY5kYaKQxZl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이미지 전처리 & Augmentation\n",
        "\n",
        "* 1. cifar10은 image의 width와 height가 똑같기 때문에 바로 224x224로 randomly crop\n",
        "\n",
        "* 2. Horizontal Flip\n",
        "\n",
        "* 3. Color Augmentation\n",
        "\n",
        "* 4. subtract the mean activity over the training set from each pixel (normalization)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NADmyI8iQ_Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = get_data(flag = True)\n",
        "\n",
        "train.transform = transforms.ToTensor()\n",
        "test.transform = transforms.ToTensor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmEEcjQWQ9N1",
        "outputId": "1f27cd2f-b780-48b9-9c39-063c35e6cb61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 15955921.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/cifar-10-python.tar.gz to /data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_meanRGB = [np.mean(x.numpy(), axis = (1, 2)) for x, _ in train]\n",
        "train_stdRGB = [np.std(x.numpy(), axis = (1, 2)) for x, _ in train]\n",
        "\n",
        "meanR = np.mean([m[0] for m in train_meanRGB])\n",
        "meanG = np.mean([m[1] for m in train_meanRGB])\n",
        "meanB = np.mean([m[2] for m in train_meanRGB])\n",
        "\n",
        "stdR = np.mean([s[0] for s in train_stdRGB])\n",
        "stdG = np.mean([s[1] for s in train_stdRGB])\n",
        "stdB = np.mean([s[2] for s in train_stdRGB])\n",
        "\n",
        "train_mean = [meanR, meanG, meanB]\n",
        "train_std = [stdR, stdG, stdB]\n",
        "\n",
        "test_meanRGB = [np.mean(x.numpy(), axis = (1, 2)) for x, _ in test]\n",
        "test_stdRGB = [np.std(x.numpy(), axis = (1, 2)) for x, _ in test]\n",
        "\n",
        "meanR = np.mean([m[0] for m in test_meanRGB])\n",
        "meanG = np.mean([m[1] for m in test_meanRGB])\n",
        "meanB = np.mean([m[2] for m in test_meanRGB])\n",
        "\n",
        "stdR = np.mean([s[0] for s in test_stdRGB])\n",
        "stdG = np.mean([s[1] for s in test_stdRGB])\n",
        "stdB = np.mean([s[2] for s in test_stdRGB])\n",
        "\n",
        "\n",
        "test_mean = [meanR, meanG, meanB]\n",
        "test_std = [stdR, stdG, stdB]\n",
        "\n",
        "print(' == == == == Train == == == ==')\n",
        "print('각 Channel당 pixel Mean 값 : ', train_mean)\n",
        "print('각 Channel당 pixel Std 값 : ', train_std)\n",
        "print(' == == == == == == == == == ==')\n",
        "\n",
        "print(' == == == == Test == == == ==')\n",
        "print('각 Channel당 pixel Mean 값 : ', test_mean)\n",
        "print('각 Channel당 pixel Std 값 : ', test_std)\n",
        "print(' == == == == == == == == == ==')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S36q_MV6Rkl3",
        "outputId": "35f1400f-8d85-4935-bf23-6bb959d8d874"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " == == == == Train == == == ==\n",
            "각 Channel당 pixel Mean 값 :  [0.49139965, 0.48215845, 0.4465309]\n",
            "각 Channel당 pixel Std 값 :  [0.20220213, 0.19931543, 0.20086348]\n",
            " == == == == == == == == == ==\n",
            " == == == == Test == == == ==\n",
            "각 Channel당 pixel Mean 값 :  [0.49421427, 0.48513138, 0.45040908]\n",
            "각 Channel당 pixel Std 값 :  [0.20189482, 0.19902097, 0.20103233]\n",
            " == == == == == == == == == ==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    transforms.ColorJitter(brightness = 0.2, contrast = 0.2, saturation = 0.2, hue = 0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_mean, train_std)\n",
        "])\n",
        "\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(test_mean, test_std)\n",
        "])\n",
        "\n",
        "# train, test 데이터셋에 대한 변환 적용\n",
        "train.transform = train_tf\n",
        "test.transform = test_tf"
      ],
      "metadata": {
        "id": "y1QT5bBUR2Sm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 설계\n"
      ],
      "metadata": {
        "id": "EUOPWoTXm-Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# == F.pad 이해하기 위함 ==\n",
        "\n",
        "sample_tensor = torch.randn(5, 3, 32, 32)\n",
        "\n",
        "# == channel을 앞 뒤로 0으로 padding ==\n",
        "out = F.pad(sample_tensor[:, :, ::2, ::2], (0, 0, 0, 0, 3, 3), \"constant\", 0)\n",
        "\n",
        "out[:,:,0]"
      ],
      "metadata": {
        "id": "Sudyv_Fryfjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class shortcut_option_A(nn.Module):\n",
        "  def __init__(self, lambd):\n",
        "    super(shortcut_option_A, self).__init__()\n",
        "    self.lambd = lambd\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lambd(x)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "\n",
        "  '''\n",
        "  BasicBlock은 resent18, 34\n",
        "  '''\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, stride = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    # == Residual Block ==\n",
        "    self.residual_function = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace = True),\n",
        "\n",
        "        nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size = 3, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "    )\n",
        "\n",
        "    # == Shortcut(Identity) ==\n",
        "    self.shortcut = nn.Sequential()\n",
        "\n",
        "    # == 만약 dimension이 맞지 않을 시에는 option(A)를 선택한다고 했음 ==\n",
        "    # == stride 2를 적용하고, channel의 size를 맞춤(앞, 뒤로 맞추기 위해 //4를 해준거임)\n",
        "    if stride != 1 or out_channels * BasicBlock.expansion != out_channels:\n",
        "      self.shortcut == shortcut_option_A(lambda x :\n",
        "                                         F.pad(x[:, :, ::2, ::2]), (0, 0, 0, 0, out_channels // 4, out_channels //4, \"constant\", 0))\n",
        "\n",
        "    def forward(self, x):\n",
        "      return nn.ReLU(inplace = True)(self.residual_function(x) + self.shortcut(x))\n",
        "\n",
        "\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))"
      ],
      "metadata": {
        "id": "bxkhlIKam_9O"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "  def __init__(self, block, num_block, num_classes = 10):\n",
        "      super(ResNet, self).__init__()\n",
        "\n",
        "      self.in_channels = 64\n",
        "\n",
        "      self.conv1 = nn.Sequential(\n",
        "          nn.Conv2d(3, 64, kernel_size = 7, stride  = 2, padding = 3, bias = False),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU(inplace = True),\n",
        "          nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "      )\n",
        "      self.conv2 = self._make_layer(block, 64, num_block[0], 1)\n",
        "      self.conv3 = self._make_layer(block, 128, num_block[1], 2)\n",
        "      self.conv4 = self._make_layer(block, 256, num_block[2], 2)\n",
        "      self.conv5 = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "      self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "      self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "      strides = [stride] + [1] * (num_blocks - 1)\n",
        "      layers = []\n",
        "\n",
        "      for stride in strides:\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "      output = self.conv1(x)\n",
        "      output = self.conv2(output)\n",
        "      x = self.conv3(output)\n",
        "      x = self.conv4(x)\n",
        "      x = self.conv5(x)\n",
        "      x = self.avg_pool(x)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = self.fc(x)\n",
        "      return x\n",
        "\n",
        "  def initialize_weights(self):\n",
        "      for m in self.modules():\n",
        "          if isinstance(m, nn.Conv2d):\n",
        "              nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "              if m.bias is not None:\n",
        "                  nn.init.constant_(m.bias, 0)\n",
        "          elif isinstance(m, nn.BatchNorm2d):\n",
        "              nn.init.constant_(m.weight, 1)\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "          elif isinstance(m, nn.Linear):\n",
        "              nn.init.normal_(m.weight, 0, 0.01)\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def resnet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "def resnet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "def resnet50():\n",
        "    return ResNet(BottleNeck, [3,4,6,3])\n",
        "\n",
        "def resnet101():\n",
        "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
        "\n",
        "def resnet152():\n",
        "    return ResNet(BottleNeck, [3, 8, 36, 3])"
      ],
      "metadata": {
        "id": "Tb6RT5Et8DoN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet50().to(device)\n",
        "torchsummary.summary(model, input_size = (3, 224, 224), device = 'cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYsO557rB2XR",
        "outputId": "2ba274d8-782d-4059-acec-976d23814015"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       BottleNeck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       BottleNeck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       BottleNeck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       BottleNeck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      BottleNeck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      BottleNeck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      BottleNeck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                   [-1, 10]          20,490\n",
            "================================================================\n",
            "Total params: 23,528,522\n",
            "Trainable params: 23,528,522\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.55\n",
            "Params size (MB): 89.75\n",
            "Estimated Total Size (MB): 376.88\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 & 검증\n",
        "\n",
        "* batch size : 256\n",
        "\n",
        "* learning rate : 0.1\n",
        "\n",
        "* momentum : 0.9\n",
        "\n",
        "* weight decay : 0.0001\n",
        "\n"
      ],
      "metadata": {
        "id": "qzEpID6JG-YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64 # 256은 너무 큼\n",
        "learning_rate = 0.1\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0001\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "abUhrB4aCqcN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# == split train, valud ==\n",
        "\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.2\n",
        "\n",
        "train_size = int(len(train) * train_ratio)\n",
        "val_size = len(train) - train_size\n",
        "\n",
        "split_train, split_train = random_split(train, [train_size, val_size])"
      ],
      "metadata": {
        "id": "UGmZ15WvHYnI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = split_train,\n",
        "                                           batch_size=  batch_size,\n",
        "                                           shuffle = True,\n",
        "                                           drop_last = True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset = split_train,\n",
        "                                        batch_size = batch_size,\n",
        "                                        shuffle = True,\n",
        "                                        drop_last = True)"
      ],
      "metadata": {
        "id": "Sw6y3HWIHZwN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = momentum, weight_decay = weight_decay)\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "z5hgW7_NHa1A"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: 반복적인 학습\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # 모델을 학습 모드로 설정\n",
        "\n",
        "\n",
        "    '''\n",
        "    1. for문 1번 반복할때마다 batch_idx는 batch_size만큼 증가\n",
        "     ex) 1 iter: 0 ~ 127\n",
        "         2 iter: 128 ~ 255\n",
        "\n",
        "         전체 훈련 데이터를 다 쓰기전까지 반복.\n",
        "    '''\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # 데이터와 레이블을 GPU로 이동 (if available)\n",
        "        # data = data.view(-1, 3, 224, 224) # multi-crop 대체\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Forward 연산\n",
        "        output = model(data)\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward 연산 및 매개변수 업데이트\n",
        "        optimizer.zero_grad() # 미분값 중복 방지\n",
        "        loss.backward() # 오차역전파\n",
        "        optimizer.step() # parameter 업데이트\n",
        "\n",
        "        # 일정 간격으로 손실 출력\n",
        "\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            #print(len(train_loader)) 항상 312로 동일한 값\n",
        "            print(batch_idx)\n",
        "            print('Epoch {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch + 1, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item())) # 100.은 실수형을 말한다.(실수형으로 출력하기 위함)\n",
        "                # len(train_loader)는 배치 개수를 나타낸다. 여기서는 312개(312번 가중치 update)\n",
        "\n",
        "    # 검증 데이터셋을 사용한 모델 평가\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # 미분값 계산 x\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Forward 계산\n",
        "            output = model(data)\n",
        "\n",
        "            val_loss += criterion(output, target).item() # 손실함수 계산\n",
        "            pred = output.argmax(dim=1, keepdim=True) # 예측값(행마다)에서 가장 큰 값의 인덱스 가져옴, (n, 1)형식\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() # target을 pred와 같은 shape으로 만들어준다.\n",
        "            '''\n",
        "            .eq()는 두 tensor의 shape이 동일해야 비교 연산이 가능하다.\n",
        "            '''\n",
        "\n",
        "    val_loss /= len(val_loader.dataset) # 검증 손실함수\n",
        "    val_accuracy = 100. * correct / len(val_loader.dataset) # 검증 정확도\n",
        "\n",
        "    # 검증 결과 출력\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        val_loss, correct, len(val_loader.dataset), val_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuW7pS8CHdIr",
        "outputId": "1a9bde8d-a57f-4446-aba2-24c7f00cee75"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch 1 [0/10000 (0%)]\tLoss: 2.635782\n",
            "100\n",
            "Epoch 1 [6400/10000 (64%)]\tLoss: 2.441854\n",
            "\n",
            "Validation set: Average loss: 0.0377, Accuracy: 1193/10000 (11.93%)\n",
            "\n",
            "0\n",
            "Epoch 2 [0/10000 (0%)]\tLoss: 2.416629\n",
            "100\n",
            "Epoch 2 [6400/10000 (64%)]\tLoss: 2.267072\n",
            "\n",
            "Validation set: Average loss: 0.0336, Accuracy: 1823/10000 (18.23%)\n",
            "\n",
            "0\n",
            "Epoch 3 [0/10000 (0%)]\tLoss: 2.156372\n",
            "100\n",
            "Epoch 3 [6400/10000 (64%)]\tLoss: 2.085773\n",
            "\n",
            "Validation set: Average loss: 0.0318, Accuracy: 2321/10000 (23.21%)\n",
            "\n",
            "0\n",
            "Epoch 4 [0/10000 (0%)]\tLoss: 2.114555\n",
            "100\n",
            "Epoch 4 [6400/10000 (64%)]\tLoss: 2.111452\n",
            "\n",
            "Validation set: Average loss: 0.0307, Accuracy: 2540/10000 (25.40%)\n",
            "\n",
            "0\n",
            "Epoch 5 [0/10000 (0%)]\tLoss: 2.003459\n",
            "100\n",
            "Epoch 5 [6400/10000 (64%)]\tLoss: 1.735039\n",
            "\n",
            "Validation set: Average loss: 0.0290, Accuracy: 3012/10000 (30.12%)\n",
            "\n",
            "0\n",
            "Epoch 6 [0/10000 (0%)]\tLoss: 1.998812\n",
            "100\n",
            "Epoch 6 [6400/10000 (64%)]\tLoss: 1.864436\n",
            "\n",
            "Validation set: Average loss: 0.0284, Accuracy: 3445/10000 (34.45%)\n",
            "\n",
            "0\n",
            "Epoch 7 [0/10000 (0%)]\tLoss: 1.794287\n",
            "100\n",
            "Epoch 7 [6400/10000 (64%)]\tLoss: 1.881827\n",
            "\n",
            "Validation set: Average loss: 0.0270, Accuracy: 3500/10000 (35.00%)\n",
            "\n",
            "0\n",
            "Epoch 8 [0/10000 (0%)]\tLoss: 1.719857\n",
            "100\n",
            "Epoch 8 [6400/10000 (64%)]\tLoss: 1.711386\n",
            "\n",
            "Validation set: Average loss: 0.0262, Accuracy: 3734/10000 (37.34%)\n",
            "\n",
            "0\n",
            "Epoch 9 [0/10000 (0%)]\tLoss: 1.728332\n",
            "100\n",
            "Epoch 9 [6400/10000 (64%)]\tLoss: 1.608865\n",
            "\n",
            "Validation set: Average loss: 0.0258, Accuracy: 3915/10000 (39.15%)\n",
            "\n",
            "0\n",
            "Epoch 10 [0/10000 (0%)]\tLoss: 1.731424\n",
            "100\n",
            "Epoch 10 [6400/10000 (64%)]\tLoss: 1.680256\n",
            "\n",
            "Validation set: Average loss: 0.0249, Accuracy: 4222/10000 (42.22%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 테스트"
      ],
      "metadata": {
        "id": "IMQrkg2CHkNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "nQ-j7WVpHfFG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1) # 가장 높은값의 인덱스, 값 반환 --> 여기서는 가장 높은 값만 반환했다.\n",
        "\n",
        "    total += labels.size(0) # 전체 데이터 예측 개수(len(cifar_test_loader) 와 같다)\n",
        "    correct += (predicted == labels.to(torch.long)).sum().item() # predicted, labels의 텐서 타입이 일치하지 않아서 long으로 바꾸어줌.\n",
        "    # 맞으면 correct에 true, 틀리면 false 반환한다. 맞은 것만 개수 센다.\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy : {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dgKnYOMHiwG",
        "outputId": "9ffe3a2d-b54f-47c0-8db7-8d6e0147c62e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 42.63\n"
          ]
        }
      ]
    }
  ]
}